# STUNIR Tools  Ada SPARK Implementation

> **⚠️ PRE-ALPHA (v0.1.0-alpha)** — See [../../VERSION_STATUS.md](../../VERSION_STATUS.md) for current capabilities.
>
> **This is the canonical entry point for the STUNIR Ada SPARK toolchain.**
> See `ARCHITECTURE.md` for the full architecture reference and `CONTRIBUTING.md`
> for governance rules. The build manifest is `stunir_tools.gpr`.

---

## ⚠️ Known Limitations (Pre-Alpha)

| Area | Limitation | Impact |
|------|------------|--------|
| **SPARK Extractor** | Multiline signatures not supported | Signatures must be on single line |
| **SPARK Extractor** | Body files (.adb) may have empty return types | Spec lookup not implemented |
| **IR Pipeline** | Deeply nested control flow limited | if-inside-while may not work |
| **Code Generation** | Stub-only output | Full function bodies not implemented |
| **Reverse Pipeline** | Code→Spec not implemented | Cannot extract from arbitrary code |

**Tested**: 11 test files, 46 functions extracted successfully. See `test_data/` for examples.

---

## ✨ Stub Alignment (NEW 2026-02-23)

The SPARK pipeline now preserves **module structure** in generated stubs:

| Structure | C/C99 | Rust | Ada/SPARK | Clojure | Prolog | Futhark | Lean4 |
|-----------|-------|------|-----------|---------|--------|----------|-------|
| **Imports** | `#include` | `use` | `with` | `:require` | `use_module` | `import` | `import` |
| **Exports** | Header | `pub` | Package spec | `defn` | module | `entry` | `def` |
| **Types** | `typedef struct` | `struct` | `type ... is record` | Comment | Comment | `type` | `structure` |
| **Constants** | `#define` | `const` | `constant` | `def` | Comment | `let` | `def` |
| **Dependencies** | Comment | Comment | Comment | Comment | Comment | Comment | Comment |

**Example IR → C Output:**

```c
// Generated by STUNIR
// Module: test_module
#include <stdio.h>
#include <math_utils.h>

typedef struct {
    i32 value;
    i32 status;
} Result;

#define MAX_SIZE 1024

// Dependencies:
//   libc @ 2.31

i32 calculate(i32 a, i32 b) {
    return a;
}
```

---

## What This Directory Is

`tools/spark/` contains the **primary Ada SPARK implementation** of the STUNIR
deterministic code generation pipeline. Ada SPARK is the default implementation
language for STUNIR tools  it provides formal verification (GNATprove), DO-178C
Level A compliance support, and hash-stable deterministic output.

The Python tools in `tools/` are an alternative pipeline. Both produce identical
IR output. Choose SPARK for formal verification; choose Python for rapid iteration.

---

## Quick Start

### Build All Tools

```bash
gprbuild -P stunir_tools.gpr
```

### Build a Single Tool

```bash
gprbuild -P stunir_tools.gpr -u ir_converter_main.adb
```

### Run SPARK Formal Verification

```bash
gnatprove -P stunir_tools.gpr --level=2
```

### Clean Build Artifacts

```bash
gprclean -P stunir_tools.gpr
```

**Requirements:** GNAT 12+ with SPARK support (FSF GNAT or GNAT Community Edition).
Precompiled binaries are available in `precompiled/linux-x86_64/spark/bin/`.

---

## The 4-Phase Pipeline

```
[Phase 0] Bootstrap
  file_indexer    source dir manifest JSON
  hash_compute    SHA-256 of any file/stdin
  lang_detect     language ID from file content
  format_detect   extraction JSON format variant

[Phase 1] Spec Assembly
  extraction JSON    spec_assembler    spec JSON
  spec JSON          spec_validate     validation result
  functions JSON     func_dedup        deduplicated functions

[Phase 2] IR Conversion
  spec JSON    ir_converter    IR JSON (stunir_flat_ir_v1)
  IR JSON      ir_validate     validation result

[Phase 3] Code Emission
  IR JSON    code_emitter       target language source
  config     pipeline_driver    full pipeline execution

[Cross-cutting]
  stunir_code_index     source code index JSON
  stunir_receipt_link   receipt JSON (spec + index linkage)
  json_extract          value at JSON path
  json_merge            merged JSON documents
  receipt_generate      verification receipt
```

The IR format is `stunir_flat_ir_v1` (flat) or `Semantic_IR` (typed AST).
See `ARCHITECTURE.md` for the full format specifications.

---

## Source Directory Structure

```
tools/spark/
 stunir_tools.gpr         SSoT build manifest (READ THIS FIRST)
 README.md                This file
 ARCHITECTURE.md          Full architecture reference
 CONTRIBUTING.md          Governance rules and contribution checklist
 schema/
    extraction_schema.json           Extraction JSON format schema
    stunir_regex_ir_v1.dcbor.json   SSoT for all regex patterns
 src/
    core/        Phase 1-4  Pipeline orchestrators + root package (stunir.ads)
    emitters/    Phase 3    STUNIR.Emitters.* code generation backends
    semantic_ir/ Phase 2    Semantic_IR.* typed AST hierarchy
    types/       Phase X    STUNIR_Types master type definitions
    json/        Phase X    JSON parsing and manipulation
    spec/        Phase 1    Spec assembly and validation
    ir/          Phase 2    IR generation, validation, optimization
    utils/       Phase X    String, path, CLI, toolchain utilities
    files/       Phase 0    Filesystem find/hash/index/read/write
    functions/   Phase 1    Function dedup, parsing, IR conversion
    detection/   Phase 0    Format and language detection
    validation/  Phase X    Schema validation
    verification/ Phase X   Hashing, manifests, receipts
 obj/             Build artifacts (.ali, .o)  never in src/
 bin/             Compiled executables
 docs/
    PIPELINE_ARCHITECTURE_ANALYSIS.md  (superseded by ARCHITECTURE.md)
    STUNIR_TYPE_ARCHITECTURE.md        (superseded by ARCHITECTURE.md)
    archive/    Historical working notes (not authoritative)
 tests/           Test sources

> **Note:** The `src/deprecated/` directory has been moved to `docs/archive/spark_deprecated/`.
> See `docs/archive/spark_deprecated/README.md` for the deprecation schedule.
```

**GOVERNANCE:** Do NOT create new subdirectories under `src/` without updating
`stunir_tools.gpr`. See `CONTRIBUTING.md` for the full checklist.

---

## Key Files for Models

If you are an AI model working with this codebase, start here:

| File | Purpose |
|------|---------|
| `stunir_tools.gpr` | **SSoT manifest**  what exists, what compiles, governance rules |
| `schema/stunir_regex_ir_v1.dcbor.json` | **SSoT for all regex patterns**  formal definitions |
| `src/core/stunir.ads` | Root package  canonical location, do not duplicate |
| `src/types/stunir_types.ads` | Master type definitions  all packages depend on this |
| `src/semantic_ir/semantic_ir-types.ads` | Semantic IR type hierarchy |
| `ARCHITECTURE.md` | Full architecture, tool catalog, format specs |
| `CONTRIBUTING.md` | Rules for adding tools, patterns, directories |

---

## Build Status

| Tool Group | Status |
|------------|--------|
| `stunir_receipt_link` |  Building |
| `stunir_code_index` |  Building |
| `stunir_spec_assemble` |  Building |
| `ir_converter` |  Fixed (2026-02-20) |
| `code_emitter` |  Fixed (2026-02-20) |
| `spec_assembler` |  Fixed (2026-02-20) |
| `pipeline_driver` |  Fixed (2026-02-20) |
| SPARK formal proofs |  In progress (level=2) |

---

## Target Languages

27 targets defined in `STUNIR_Types.Target_Language`:

**Canonical Emitter Path:** The Micro IR emitter (`src/emitters/emit_target.adb`) is the
unified code generation backend. The typed Semantic IR emitters (`STUNIR.Emitters.*`)
are deprecated and scheduled for removal on 2026-06-01.

| Target Family | Targets | Status |
|---------------|---------|--------|
| **Mainstream** | C, C++, Python, Rust, Go, Java, JavaScript, C#, Swift, Kotlin, SPARK, Ada |  Implemented |
| **Lisp Family** | Common Lisp, Scheme, Racket, Emacs Lisp, Guile, Hy, Janet, Clojure, ClojureScript |  Implemented |
| **Prolog Family** | SWI-Prolog, GNU-Prolog, Mercury, Prolog (generic) |  Implemented |
| **Functional/Formal** | Futhark, Lean 4, Haskell |  Implemented |

All targets support the same IR step coverage:
- `Step_Assign`, `Step_Call`, `Step_Return`
- `Step_If` with nested then/else blocks
- `Step_While` with nested body blocks
- `Step_For` with nested body blocks

### Target Extensions

| Target | Extension |
|--------|----------|
| Common Lisp | `.lisp` |
| Scheme/Guile | `.scm` |
| Racket | `.rkt` |
| Emacs Lisp | `.el` |
| Hy | `.hy` |
| Janet | `.janet` |
| Clojure | `.clj` |
| ClojureScript | `.cljs` |
| SWI/GNU Prolog | `.pl` |
| Mercury | `.m` |
| Futhark | `.fut` |
| Lean 4 | `.lean` |
| Haskell | `.hs` |
| Ada/SPARK | `.adb` |

---

## Self-Refinement

STUNIR can run its own pipeline on its own SPARK source code. This self-refinement
capability enables analysis and validation of the toolchain by the toolchain itself.

### Running Self-Refinement

**PowerShell (Windows):**
```powershell
cd tools/spark
.\self_refine.ps1 -Verbose
```

**Bash (Linux/WSL):**
```bash
cd tools/spark
chmod +x self_refine.sh
./self_refine.sh --verbose
```

### Self-Refinement Options

| Option | Description |
|--------|-------------|
| `-o, --output DIR` | Output directory (default: `work_artifacts/analysis/self_refine`) |
| `-t, --targets LIST` | Comma-separated targets (default: `SPARK,Ada`) |
| `-v, --verbose` | Enable verbose output |
| `-s, --skip-emission` | Skip code emission phase |
| `-h, --help` | Show help |

### Self-Refinement Phases

1. **Phase 0**: Enumerate SPARK source files from `src/` and `tests/spark/`
2. **Phase 1**: Run extraction on each source file
3. **Phase 2**: Aggregate extractions into a unified spec
4. **Phase 3**: Convert spec to IR
5. **Phase 4**: Validate IR against schema
6. **Phase 5**: Emit target code (SPARK, Ada, etc.)

### Success Criteria

The default success criterion is **IR + schema validation passes**. This ensures:
- All source files are processed
- Generated IR conforms to `stunir_ir_v1` schema
- No critical errors in the pipeline

### Output Artifacts

```
work_artifacts/analysis/self_refine/
├── extraction/          # Per-file extraction JSON
├── spec/                # Aggregated spec JSON
├── ir/                  # Generated IR JSON
├── emit/                # Emitted target code
│   ├── spark/           # SPARK output
│   └── ada/             # Ada output
└── reports/
    ├── self_refine_report.json    # Machine-readable report
    └── self_refine_summary.txt    # Human-readable summary
```

### Current Limitations

- **Extraction**: SPARK extraction uses `spark_extract_main` (minimal signature parser).
   Full AST extraction is planned next; until then, deep semantic details are not captured.
- **IR Conversion**: Generates placeholder steps (assign + return)
- **Emission**: Uniform step coverage (assign/call/return/if/while/for)

These limitations are expected and will be improved in future versions.

---

## Binary Deprecation Policy

**Only tools in `stunir_tools.gpr` Main list are surfaced.** Extra binaries are
moved to `bin/deprecated/` to avoid confusing downstream tooling and models.

### Updated Tools (27)

These are the canonical tools from the GPR Main list:

| Phase | Tools |
|-------|-------|
| **Phase 0** | `file_indexer`, `hash_compute`, `lang_detect`, `format_detect`, `toolchain_verify`, `source_extract_main` |
| **Phase 1** | `spec_assembler_main`, `stunir_spec_assemble_main`, `extraction_to_spec`, `assemble_spec_main`, `func_dedup`, `type_normalize` |
| **Phase 2** | `ir_converter_main`, `ir_canonicalize_dcbor`, `ir_validate_schema`, `ir_validate`, `type_map`, `spec_to_ir_main` |
| **Phase 3** | `code_emitter_main`, `pipeline_driver_main`, `emit_target_main` |
| **Cross-cutting** | `stunir_code_index_main`, `stunir_receipt_link_main`, `json_validate`, `json_extract`, `json_merge`, `receipt_generate` |

### Deprecated Tools (54)

These tools are in `bin/deprecated/` and will be removed on **2026-06-01**:

- Code generation helpers: `code_add_comments`, `code_format_target`, `code_gen_func_body`, `code_gen_func_sig`, `code_gen_preamble`, `code_write`
- CPP utilities: `cpp_header_gen`, `cpp_impl_gen`, `cpp_sig_normalize`
- File utilities: `file_find`, `file_hash`, `file_writer`
- Function analysis: `func_parse_body`, `func_parse_sig`, `func_to_ir`
- IR utilities: `ir_add_metadata`, `ir_check_functions`, `ir_check_required`, `ir_check_types`, `ir_extract_funcs`, `ir_extract_module`, `ir_gen_functions`, `ir_merge_funcs`
- JSON utilities: `json_formatter`, `json_merge_arrays`, `json_merge_objects`, `json_path_eval`, `json_path_parser`, `json_validator`, `json_value_format`
- Other: `manifest_generate`, `module_to_ir`, `schema_check_format`, `schema_check_required`, `schema_check_types`, `sig_gen_cpp`, `sig_gen_python`, `sig_gen_rust`, `spec_extract_funcs`, `spec_extract_module`, `spec_extract_types`, `spec_to_python`, `spec_validate`, `spec_validate_schema`, `stunir_ir_to_code_main`, `stunir_spec_to_ir_main`, `type_dependency`, `type_expand`, `type_lookup`, `type_map_cpp`, `type_map_target`, `type_resolve`, `type_resolver`, `validation_reporter`

### Running Deprecation

To move extra binaries to the deprecated folder:

```bash
cd tools/spark/bin
./deprecate_extras.cmd   # Windows
```

---

## Regex Patterns

All regular expressions used in this toolchain are canonically defined in:

```
schema/stunir_regex_ir_v1.dcbor.json
```

This file is a normalized semantic AST dCBOR JSON intermediate reference  the
same format the pipeline generates. It covers 13 pattern groups:

- `validation.hash`  SHA-256 hash formats
- `validation.node_id`  Semantic IR node IDs
- `validation.identifier`  Programming language identifiers
- `extraction.c_function`  C function signature extraction
- `extraction.whitespace`  Whitespace normalization
- `asm.x86_registers` / `asm.arm_registers` / `asm.wasm_instructions`
- `asm.x86_instructions` / `asm.arm_instructions`
- `asm.unsafe_syscall` / `asm.directives`
- `logging.filter`  Runtime-supplied log filter patterns
- `sanitization.identifier` / `sanitization.tool_name`

When adding a new pattern to any source file, add it to the regex IR first.

---

## Ada SPARK Philosophy

STUNIR uses Ada SPARK because:

1. **Determinism**  SPARK's formal contracts guarantee the same inputs always
   produce the same outputs. No hidden state, no undefined behavior.

2. **DO-178C compliance**  GNATprove can produce evidence for DO-178C Level A
   (absence of runtime errors, functional correctness proofs).

3. **Hash-stable output**  Canonical IR is produced by deterministic SPARK code,
   not by a model. Models propose; SPARK tools commit.

4. **Small verifiers**  SPARK's type system and contracts make the verification
   logic simpler than the generation logic (a key STUNIR design principle).

---

## Copyright

Copyright (c) 2026 STUNIR Project  License: MIT
