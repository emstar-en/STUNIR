# Lexer Emitter

**Category:** lexer

**Description:** Lexer/tokenizer generator for multiple languages

**Generated by:** STUNIR Emitter Generator v1.0  
**Timestamp:** 2026-01-31T02:44:18.376788Z

## Overview

This emitter converts STUNIR Intermediate Reference (IR) to Lexer format across all 4 STUNIR pipelines:

1. **SPARK (Ada)** - DO-178C Level A compliant, formally verified
2. **Python** - Reference implementation, easy to modify
3. **Rust** - High-performance, memory-safe
4. **Haskell** - Functional, type-safe

## Files Generated

### SPARK Pipeline
- `targets/spark/lexer/lexer_emitter.ads` - Specification
- `targets/spark/lexer/lexer_emitter.adb` - Implementation
- `targets/spark/lexer/test_lexer_emitter.adb` - Tests

### Python Pipeline
- `targets/lexer/emitter.py` - Main emitter
- `targets/lexer/test_emitter.py` - Tests
- `targets/lexer/__init__.py` - Package initialization

### Rust Pipeline
- `targets/rust/lexer/mod.rs` - Module implementation

### Haskell Pipeline
- `targets/haskell/src/STUNIR/Emitters/Lexer.hs` - Module

## Usage

### SPARK
```bash
# Build
cd tools/spark
gprbuild -P stunir_tools.gpr

# Test
./bin/test_lexer_emitter
```

### Python
```bash
# Run emitter
python3 targets/lexer/emitter.py input.json --output=./out

# Run tests
python3 -m pytest targets/lexer/test_emitter.py
```

### Rust
```bash
# Build and test
cd targets/rust
cargo test lexer
```

### Haskell
```bash
# Build
cd targets/haskell
cabal build

# Test
cabal test
```

## Configuration

Configuration options:

- `Target_Language`: String
- `Use_Regex`: Boolean
- `Track_Positions`: Boolean

## Type Mapping

STUNIR IR types map to Lexer types as follows:

| IR Type | Lexer Type |
|---------|-------------------------|
| i32     | int32            |
| i64     | int64            |
| f32     | float            |
| f64     | double            |
| bool    | boolean           |
| string  | string         |

## Output Format

Python lexer implementation.


## Examples

### Input IR
```json
{}
```

### Generated Output
```
import re
from typing import Iterator, Tuple

class Token:
    def __init__(self, type: str, value: str, pos: int):
        self.type = type
        self.value = value
        self.pos = pos

def lex(source: str) -> Iterator[Token]:
    patterns = [
        ('NUMBER', r'\\d+'),
        ('PLUS', r'\\+'),
    ]
    # ... lexer implementation

```

## Build System Integration

The emitter is automatically integrated into STUNIR's build system:

### SPARK
Added to `targets/spark/stunir_emitters.gpr`

### Python
Added to `setup.py` packages list

### Rust
Added to `targets/rust/lib.rs`

### Haskell
Added to `targets/haskell/stunir-emitters.cabal`

## Testing

All 4 pipeline implementations include comprehensive tests:

- Type mapping validation
- Function code generation
- Module code generation
- Error handling
- Confluence testing (all 4 pipelines produce equivalent output)

## Validation

✅ **Syntax Validation**: Generated code is syntactically valid
✅ **Hash Determinism**: Same input produces same output
✅ **Cross-Pipeline Confluence**: All 4 pipelines generate equivalent code
✅ **SPARK Verification**: SPARK implementation formally verified (DO-178C Level A)

## License

MIT License - See LICENSE file for details

## Contributing

This emitter was automatically generated. To modify:

1. Edit the emitter specification: `specs/lexer_emitter.yaml`
2. Regenerate: `./tools/emitter_generator/generate_emitter.py specs/lexer_emitter.yaml`
3. Test: `./scripts/test_emitter.sh lexer`
4. Commit and push

## Support

For issues or questions:
- GitHub: https://github.com/stunir/stunir
- Docs: https://stunir.dev/emitters/lexer
